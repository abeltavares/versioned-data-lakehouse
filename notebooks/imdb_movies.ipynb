{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87cba03-4309-4d12-b3a6-4f80bca971fa",
   "metadata": {},
   "source": [
    "### 🎬 **Versioned Data Lakehouse with Apache Iceberg and Spark**\n",
    "\n",
    "This notebook demonstrates how to use **Project Nessie** as a transactional catalog for **Apache Iceberg** tables in a data lakehouse. Key features include:\n",
    "\n",
    "-   **Versioning**: Track changes to your data over time.\n",
    "\n",
    "-   **Branching and Merging**: Create branches for experimental changes and merge them back into the main branch.\n",
    "\n",
    "-   **Tags**: Create immutable snapshots of your data for reproducibility and auditing.\n",
    "\n",
    "* * * * *\n",
    "\n",
    "### 🎯 **Project Overview**\n",
    "\n",
    "We will build an **ETL pipeline** for IMDb movie data using Nessie's branching and versioning capabilities.\n",
    "\n",
    "1.  **Raw Data Ingestion**: Load raw IMDb data into a `raw` branch.\n",
    "\n",
    "2.  **Data Transformation**: Clean and transform the data in a `dev` branch.\n",
    "\n",
    "3.  **Data Validation**: Perform quality checks before promoting data to production.\n",
    "\n",
    "4.  **Promotion to Main**: Merge the validated data into the `main` branch.\n",
    "\n",
    "5.  **Versioning and Time Travel**: Use tags and commit hashes to track changes and time travel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242cefe3-698d-4614-8d8d-04263c825d1c",
   "metadata": {},
   "source": [
    "Configure Spark to use Nessie as the catalog and Iceberg as the table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed884332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Stop existing Spark session if running\n",
    "if 'spark' in globals():\n",
    "    spark.stop()\n",
    "\n",
    "# Initialize Spark with Iceberg and Nessie integrations\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NessieIMDbDemo\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ Spark session started with Nessie and Iceberg.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cda92a-2eac-4eca-879f-c84e66c4a5e0",
   "metadata": {},
   "source": [
    "Create a namespace for IMDb data and a raw branch for ingesting raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d12095e-48ad-46da-9b09-e54130723c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the namespace\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS imdb\")\n",
    "\n",
    "# Create a raw branch\n",
    "spark.sql(\"CREATE BRANCH IF NOT EXISTS raw FROM main\")\n",
    "spark.sql(\"USE REFERENCE raw\")\n",
    "print(\"✅ Created and switched to 'raw' branch for raw data ingestion.\")\n",
    "\n",
    "# List references to verify the branch creation\n",
    "print(\"📋 List of references:\")\n",
    "spark.sql(\"LIST REFERENCES\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3cdfe5-e0ec-49f1-a85d-e685346ff805",
   "metadata": {},
   "source": [
    "Load the raw IMDb data into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d922bccd-f734-4845-918d-f2fc64ba9c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = spark.read.option(\"header\", \"true\").csv(\"/home/iceberg/data/imdb-movies.csv\")\n",
    "\n",
    "# Explore the raw dataset\n",
    "print(\"📋 First 5 rows of raw IMDb data:\")\n",
    "raw_df.show(5)\n",
    "\n",
    "print(\"📋 Schema of raw IMDb data:\")\n",
    "raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd7896-765f-4f55-9dd7-99f86554cbf5",
   "metadata": {},
   "source": [
    "Create an Iceberg table in the `raw` branch to store the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c98a17-804c-41b7-bb57-bdd16987810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS nessie.imdb.movies (\n",
    "        imdb_title_id STRING,\n",
    "        title STRING,\n",
    "        year INT,\n",
    "        genre STRING,\n",
    "        director STRING,\n",
    "        avg_vote DOUBLE,\n",
    "        votes INT\n",
    "    )\n",
    "    USING iceberg\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ Iceberg table 'movies' created in the 'raw' branch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1df790-9588-4c86-bc23-a2f1c9189339",
   "metadata": {},
   "source": [
    "Insert the raw data into the `movies` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721552b-29f0-41a8-b0fb-7cf5f96d24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.select(\n",
    "    col(\"imdb_title_id\"),\n",
    "    col(\"title\"),\n",
    "    col(\"year\").cast(\"int\"),\n",
    "    col(\"genre\"),\n",
    "    col(\"director\"),\n",
    "    col(\"avg_vote\").cast(\"double\"),\n",
    "    col(\"votes\").cast(\"int\")\n",
    ").writeTo(\"nessie.imdb.movies\").append()\n",
    "\n",
    "print(\"✅ Raw data ingested into 'movies' in the 'raw' branch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcfcf3f-23ea-4600-9e26-7d9fa1b3c47a",
   "metadata": {},
   "source": [
    "Verify existince of the `movie` table and data has been ingested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14350b2-e223-402e-91f2-fbf04a8c5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📋 Tables in the 'raw' branch:\")\n",
    "spark.sql(\"SHOW TABLES IN nessie.imdb\").show(truncate=False)\n",
    "\n",
    "print(\"📋 Raw data in the 'raw' branch:\")\n",
    "spark.sql(\"SELECT * FROM nessie.imdb.movies\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460ba6b-5693-476a-ad58-69bd3e3564f9",
   "metadata": {},
   "source": [
    "Describe the Iceberg table to view its properties and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a00505-e306-4208-ab09-348ecac02f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📋 Table description for 'movies':\")\n",
    "spark.sql(\"DESCRIBE TABLE EXTENDED nessie.imdb.movies\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8637f4-87f4-417c-baac-d2a481ee0d52",
   "metadata": {},
   "source": [
    "Create a `dev` branch from the `raw` branch to perform transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ebde5d-87d0-4b3d-bad7-e2aea816c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dev branch from raw\n",
    "spark.sql(\"CREATE BRANCH dev FROM raw\")\n",
    "spark.sql(\"USE REFERENCE dev\")\n",
    "print(\"✅ Created and switched to 'dev' branch for transformations.\")\n",
    "\n",
    "print(\"📋 List of references:\")\n",
    "spark.sql(\"LIST REFERENCES\").toPandas()\n",
    "\n",
    "print(\"📋 Tables in the 'dev' branch:\")\n",
    "spark.sql(\"SHOW TABLES IN nessie.imdb\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242f759-d39e-4892-9936-f78969401fc8",
   "metadata": {},
   "source": [
    "Before performing transformations, record the commit hash to enable time travel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d41628-dd3e-45b0-90b1-58a14bf60daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_hash_before_cleaning = spark.sql(\"SHOW REFERENCE\").filter(\"name = 'dev'\").select(\"hash\").collect()[0][0]\n",
    "print(f\"Commit hash before cleaning: {commit_hash_before_cleaning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b499c52-4380-4492-9582-edf87ea88a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query records that will be cleaned (null directors or avg_vote <= 5)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM nessie.imdb.movies\n",
    "    WHERE director IS NULL OR avg_vote <= 5\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a17f83-ed43-4cf0-a134-883a8c889b1a",
   "metadata": {},
   "source": [
    "Perform transformations and cleaning directly in the `movies` table in the `dev` branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87748491-8198-4826-877d-dd9d475df904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and clean data\n",
    "spark.sql(\"\"\"\n",
    "    UPDATE nessie.imdb.movies\n",
    "    SET director = 'Unknown'\n",
    "    WHERE director IS NULL\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    DELETE FROM nessie.imdb.movies\n",
    "    WHERE avg_vote <= 5\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ Data transformed and cleaned directly in 'movies' in the 'dev' branch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae01251-69a6-43dd-8ef7-3fdd5f6c4ad1",
   "metadata": {},
   "source": [
    "Nessie and Iceberg support time travel, allowing you to query data as it existed at a specific point in time. Let’s use the commit hash recorded earlier to query the data before transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6cc7e-7cda-4f2f-a84f-77d23469a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current state of dev\n",
    "print(\"Data in 'dev' branch after transformations:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM nessie.imdb.movies\n",
    "    WHERE director IS NULL OR avg_vote <= 5\n",
    "    LIMIT 5\n",
    "\"\"\").show()\n",
    "\n",
    "# Time Travel Query to confirm cleaned data is retrievable\n",
    "print(\"📋 Data before transformations (using commit hash):\")\n",
    "spark.sql(f\"\"\"\n",
    "    -- Note: The `dev` branch is the current reference, so we don't need to specify it explicitly.\n",
    "    -- However, you can explicitly reference a branch or commit hash like this: `table@branch#commithash`\n",
    "    SELECT * FROM imdb.`movies@dev#{commit_hash_before_cleaning}`\n",
    "    WHERE director IS NULL OR avg_vote <= 5\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc2b99-a8fd-4995-a2ab-e7c82933b618",
   "metadata": {},
   "source": [
    "Perform data quality checks before promoting the data to `main`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c5990-d3c0-43f5-b852-38ac23c5bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data: Check for data quality issues\n",
    "validation_df = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS total_movies,\n",
    "           SUM(CASE WHEN director = 'Unknown' THEN 1 ELSE 0 END) AS unknown_director,\n",
    "           SUM(CASE WHEN avg_vote <= 5 THEN 1 ELSE 0 END) AS low_rated_movies\n",
    "    FROM nessie.imdb.movies\n",
    "\"\"\")\n",
    "\n",
    "validation_df.show()\n",
    "\n",
    "# Check for validation errors\n",
    "if validation_df.filter(col(\"unknown_director\") > 0).count() > 0:\n",
    "    print(\"❌ Validation failed: Some movies have unknown directors.\")\n",
    "elif validation_df.filter(col(\"low_rated_movies\") > 0).count() > 0:\n",
    "    print(\"❌ Validation failed: Some movies have low ratings.\")\n",
    "else:\n",
    "    print(\"✅ Validation passed: Data is clean and ready for promotion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae08bd1-4b3d-4d10-8715-bb5eb1259c8f",
   "metadata": {},
   "source": [
    "Merge the dev branch into the `main` branch to promote the validated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829acf7-f736-4f9d-9744-e400c7364728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dev branch into main\n",
    "spark.sql(\"MERGE BRANCH dev INTO main\")\n",
    "print(\"✅ 'dev' branch merged into 'main'. Transformed data is now in production.\")\n",
    "\n",
    "# Query data in the main branch to verify the merge\n",
    "print(\"📋 Data in the 'main' branch after merge:\")\n",
    "spark.sql(\"SELECT * FROM nessie.imdb.movies\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51730974-f220-4067-840d-2686a3945583",
   "metadata": {},
   "source": [
    "Create a tag to mark this version of the data as stable for reporting or auditing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411d6e48-c0d6-4374-ab04-e0d311b4b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tag for reporting\n",
    "spark.sql(\"\"\"\n",
    "    -- Create a tag named 'report_202501' at the current state of 'main'.\n",
    "    -- This tag can be used to query the data as it exists at this point in time.\n",
    "    -- Example: SELECT * FROM imdb.`movies@report_202501`\n",
    "    CREATE TAG IF NOT EXISTS report_202501\n",
    "\"\"\")\n",
    "print(\"✅ Tag 'report_202501' created at the current state of 'main'.\")\n",
    "\n",
    "# List references to verify the tag creation\n",
    "print(\"📋 List of references:\")\n",
    "spark.sql(\"LIST REFERENCES\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805271ce-d141-46ca-af9f-ef4b59832c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up: Delete the raw and dev branches\n",
    "spark.sql(\"DROP BRANCH IF EXISTS raw\")\n",
    "spark.sql(\"DROP BRANCH IF EXISTS dev\")\n",
    "print(\"✅ 'raw' and 'dev' branches deleted.\")\n",
    "\n",
    "# Clean up: Delete the tag\n",
    "spark.sql(\"DROP TAG IF EXISTS report_202501\")\n",
    "print(\"✅ Tag 'report_202501' deleted.\")\n",
    "\n",
    "# Cleanup Spark\n",
    "spark.stop()\n",
    "print(\"✅ Spark session stopped and resources cleaned up.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
